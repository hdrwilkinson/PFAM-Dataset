{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7732d883",
   "metadata": {},
   "source": [
    "# Experiment Overview\n",
    "\n",
    "I conducted a supplementary experiment employing the Transformer architecture to investigate the effects of various oversampling strategies on addressing the challenges posed by imbalanced class distributions in the PFAM dataset. My objective was to examine the impact of these oversampling approaches on the F1 score, a critical performance metric in protein family classification, particularly in the presence of imbalanced datasets.\n",
    "\n",
    "To create the five subsets of the PFAM dataset with distinct levels of imbalance, I selected 100 classes of varying popularity for each train|val|test split. Popularity, in this context, is a measure of the number of samples per class in the dataset. The classes were chosen starting with the most popular and incrementing through the dataset with factors of 1, 3, 10, 30, and 100, resulting in subsets designated as Iter1, Iter3, Iter10, Iter30, and Iter100.\n",
    "\n",
    "For each dataset, I assessed four distinct oversampling methods: \"none\", \"regular\", \"sqrt\", and \"efficient\".\n",
    "\n",
    "None: In this baseline approach, no oversampling was applied during the training and validation steps, enabling me to assess the performance of the Transformer architecture without any sampling modifications.\n",
    "\n",
    "Regular: Building upon the baseline, I implemented a straightforward oversampling method that adjusts sample selection probabilities inversely proportional to class frequencies. This approach enhances the representation of underrepresented classes, potentially improving overall classification performance.\n",
    "\n",
    "Sqrt: To further refine the oversampling process, I introduced a square root weighting scheme that adjusts the class probabilities, increasing the likelihood of sampling less common classes while mitigating the risk of overfitting associated with the regular oversampling method.\n",
    "\n",
    "Efficient: In my final approach, I employed a re-weighting method based on the concept of \"effective number of samples\", as proposed in a CVPR'19 research paper by Google. This method introduces a parameter, ùõΩ, and aims to strike a balance between regular oversampling and more complex techniques, offering the potential for superior classification performance on imbalanced datasets.\n",
    "\n",
    "The performance of each oversampling method was evaluated using the F1 score on a test set, with models being trained using separate training and validation sets. All testing was conducted using \"regular\" oversampling for a fair comparison of the learning capabilities of less visible classes across different techniques.\n",
    "\n",
    "Through this systematic investigation, I aimed to provide valuable insights into the effectiveness of various oversampling approaches in addressing imbalanced class distributions in the context of protein family classification using Transformer models. The results of my study may have practical implications for researchers and practitioners in the field of bioinformatics and drug discovery, enabling them to more effectively classify protein sequences and identify potential drug targets for developing new treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad3b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operations import oversampling_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20835a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling = [\"none\", \"regular\", \"sqrt\", \"beta\"]\n",
    "class_gaps = [1, 3, 10, 30, 100]\n",
    "model_parameters = {'embed_size': 128, 'hidden_dim': 235, 'feed_forward_dim': 373, 'num_layers': 3, 'num_heads': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4c9cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training gap 1 with oversampling none.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.04, train f1: 0.29, val loss: 0.03, val f1: 0.55, duration: 32.8s\n",
      "Epoch   5/ 10, train loss: 0.00, train f1: 0.94, val loss: 0.00, val f1: 0.94, duration: 36.0s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.98, val loss: 0.00, val f1: 0.98, duration: 35.7s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.9850182158396913\n",
      "\n",
      "\n",
      "\n",
      "Training gap 3 with oversampling none.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.24, val loss: 0.03, val f1: 0.48, duration: 27.5s\n",
      "Epoch   5/ 10, train loss: 0.00, train f1: 0.93, val loss: 0.00, val f1: 0.94, duration: 28.8s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.97, val loss: 0.00, val f1: 0.98, duration: 28.7s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.9766876674319\n",
      "\n",
      "\n",
      "\n",
      "Training gap 10 with oversampling none.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.10, val loss: 0.04, val f1: 0.17, duration: 19.4s\n",
      "Epoch   5/ 10, train loss: 0.01, train f1: 0.82, val loss: 0.01, val f1: 0.83, duration: 18.6s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.93, val loss: 0.00, val f1: 0.93, duration: 18.5s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.9268734823353347\n",
      "\n",
      "\n",
      "\n",
      "Training gap 30 with oversampling none.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.04, val loss: 0.06, val f1: 0.07, duration: 10.4s\n",
      "Epoch   5/ 10, train loss: 0.02, train f1: 0.48, val loss: 0.04, val f1: 0.33, duration: 10.2s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.70, val loss: 0.02, val f1: 0.60, duration: 10.1s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.6280952523026735\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling none.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.02, val loss: 0.07, val f1: 0.01, duration: 5.2s\n",
      "Epoch   5/ 10, train loss: 0.02, train f1: 0.23, val loss: 0.05, val f1: 0.17, duration: 5.1s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.57, val loss: 0.03, val f1: 0.45, duration: 5.3s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.44042040329873416\n",
      "\n",
      "\n",
      "\n",
      "Training gap 1 with oversampling regular.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.04, train f1: 0.33, val loss: 0.03, val f1: 0.64, duration: 36.2s\n",
      "Epoch   5/ 10, train loss: 0.00, train f1: 0.94, val loss: 0.00, val f1: 0.95, duration: 36.0s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.98, val loss: 0.00, val f1: 0.99, duration: 36.2s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.9872607920373347\n",
      "\n",
      "\n",
      "\n",
      "Training gap 3 with oversampling regular.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.29, val loss: 0.03, val f1: 0.54, duration: 27.9s\n",
      "Epoch   5/ 10, train loss: 0.00, train f1: 0.93, val loss: 0.00, val f1: 0.95, duration: 28.2s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.98, val loss: 0.00, val f1: 0.98, duration: 28.5s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.9835771966448792\n",
      "\n",
      "\n",
      "\n",
      "Training gap 10 with oversampling regular.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.19, val loss: 0.04, val f1: 0.32, duration: 17.8s\n",
      "Epoch   5/ 10, train loss: 0.01, train f1: 0.85, val loss: 0.01, val f1: 0.87, duration: 18.5s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.94, val loss: 0.00, val f1: 0.95, duration: 19.1s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.9466478467502926\n",
      "\n",
      "\n",
      "\n",
      "Training gap 30 with oversampling regular.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.11, val loss: 0.05, val f1: 0.19, duration: 11.0s\n",
      "Epoch   5/ 10, train loss: 0.02, train f1: 0.62, val loss: 0.03, val f1: 0.49, duration: 10.7s\n",
      "Epoch  10/ 10, train loss: 0.02, train f1: 0.76, val loss: 0.01, val f1: 0.75, duration: 10.5s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.7430678088022498\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling regular.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.06, val loss: 0.06, val f1: 0.08, duration: 5.1s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.56, val loss: 0.03, val f1: 0.57, duration: 5.6s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.82, val loss: 0.01, val f1: 0.80, duration: 5.4s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.82177727411851\n",
      "\n",
      "\n",
      "\n",
      "Training gap 1 with oversampling sqrt.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.04, train f1: 0.33, val loss: 0.03, val f1: 0.59, duration: 36.1s\n",
      "Epoch   5/ 10, train loss: 0.00, train f1: 0.95, val loss: 0.00, val f1: 0.96, duration: 37.7s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.98, val loss: 0.00, val f1: 0.98, duration: 35.4s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.9852584094949841\n",
      "\n",
      "\n",
      "\n",
      "Training gap 3 with oversampling sqrt.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.28, val loss: 0.03, val f1: 0.48, duration: 27.4s\n",
      "Epoch   5/ 10, train loss: 0.00, train f1: 0.93, val loss: 0.00, val f1: 0.94, duration: 28.7s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.98, val loss: 0.00, val f1: 0.98, duration: 30.9s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.981151458804347\n",
      "\n",
      "\n",
      "\n",
      "Training gap 10 with oversampling sqrt.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.14, val loss: 0.04, val f1: 0.27, duration: 19.7s\n",
      "Epoch   5/ 10, train loss: 0.01, train f1: 0.84, val loss: 0.01, val f1: 0.87, duration: 17.8s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.94, val loss: 0.00, val f1: 0.95, duration: 18.1s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.9472495666754491\n",
      "\n",
      "\n",
      "\n",
      "Training gap 30 with oversampling sqrt.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.06, val loss: 0.05, val f1: 0.09, duration: 11.0s\n",
      "Epoch   5/ 10, train loss: 0.02, train f1: 0.58, val loss: 0.03, val f1: 0.53, duration: 10.5s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.78, val loss: 0.02, val f1: 0.72, duration: 10.5s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.7164578083427428\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling sqrt.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.03, val loss: 0.06, val f1: 0.07, duration: 5.2s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.44, val loss: 0.03, val f1: 0.46, duration: 5.4s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.77, val loss: 0.02, val f1: 0.76, duration: 5.0s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.7644219893133976\n",
      "\n",
      "\n",
      "\n",
      "Training gap 1 with oversampling beta.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.04, train f1: 0.29, val loss: 0.03, val f1: 0.55, duration: 36.2s\n",
      "Epoch   5/ 10, train loss: 0.00, train f1: 0.95, val loss: 0.00, val f1: 0.96, duration: 36.7s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.98, val loss: 0.00, val f1: 0.98, duration: 36.3s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.9841236502105604\n",
      "\n",
      "\n",
      "\n",
      "Training gap 3 with oversampling beta.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.23, val loss: 0.03, val f1: 0.45, duration: 27.9s\n",
      "Epoch   5/ 10, train loss: 0.01, train f1: 0.90, val loss: 0.00, val f1: 0.93, duration: 27.8s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.97, val loss: 0.00, val f1: 0.98, duration: 28.1s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.9768875267220756\n",
      "\n",
      "\n",
      "\n",
      "Training gap 10 with oversampling beta.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.10, val loss: 0.04, val f1: 0.17, duration: 17.8s\n",
      "Epoch   5/ 10, train loss: 0.01, train f1: 0.82, val loss: 0.01, val f1: 0.84, duration: 18.6s\n",
      "Epoch  10/ 10, train loss: 0.00, train f1: 0.93, val loss: 0.00, val f1: 0.94, duration: 18.2s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.933422173027994\n",
      "\n",
      "\n",
      "\n",
      "Training gap 30 with oversampling beta.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.04, val loss: 0.06, val f1: 0.04, duration: 9.9s\n",
      "Epoch   5/ 10, train loss: 0.02, train f1: 0.47, val loss: 0.03, val f1: 0.42, duration: 10.2s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.71, val loss: 0.02, val f1: 0.66, duration: 10.1s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.6378060650159864\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling beta.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/ 10, train loss: 0.05, train f1: 0.02, val loss: 0.07, val f1: 0.00, duration: 5.2s\n",
      "Epoch   5/ 10, train loss: 0.02, train f1: 0.24, val loss: 0.05, val f1: 0.18, duration: 5.2s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.56, val loss: 0.03, val f1: 0.49, duration: 5.3s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.4361624423919399\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversampling_training(oversampling, class_gaps, model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875280f2",
   "metadata": {},
   "source": [
    "## Experiment Continuation: SQRT vs Regular\n",
    "\n",
    "To further investigate the impact of oversampling strategies on addressing imbalanced class distributions in the PFAM dataset, I conducted an extension to the previous experiment focusing on two oversampling methods: \"regular\" and \"sqrt\". The objective was to evaluate the effectiveness of these methods in addressing class imbalance and to determine if the previous finding that \"regular\" was superior to \"sqrt\" was consistent across multiple repetitions of the experiment.\n",
    "\n",
    "To achieve this objective, I repeated Iter100 five times for each \"regular\" and \"sqrt\" oversampling method, with the goal of obtaining a more accurate estimate of the average improvement in F1 score for each method. The experiment used the same evaluation metrics and methodology as the previous experiment, with the F1 score being used to assess the performance of each oversampling method on a test set.\n",
    "\n",
    "The results of this experiment extension may provide valuable insights into the effectiveness of different oversampling methods for addressing imbalanced class distributions in the context of protein family classification using Transformer models. The findings may have practical implications for researchers and practitioners in the field of bioinformatics and drug discovery, potentially enabling more effective classification of protein sequences and identification of potential drug targets for developing new treatments.\n",
    "\n",
    "Overall, this experiment extension represents a continuation of the systematic investigation into the most effective oversampling methods for protein family classification from the PFAM dataset using Transformer models, aiming to contribute to the growing body of knowledge in this challenging field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093255ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_gaps = [100] * 5\n",
    "oversampling = [\"regular\", \"sqrt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5eddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training gap 100 with oversampling regular.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.08, val loss: 0.06, val f1: 0.11, duration: 4.9s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.56, val loss: 0.03, val f1: 0.60, duration: 4.5s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.82, val loss: 0.01, val f1: 0.84, duration: 4.9s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.8059445557740575\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling regular.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.08, val loss: 0.06, val f1: 0.10, duration: 5.4s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.58, val loss: 0.03, val f1: 0.60, duration: 4.8s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.83, val loss: 0.01, val f1: 0.82, duration: 4.7s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.8223581927355617\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling regular.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.08, val loss: 0.06, val f1: 0.11, duration: 4.9s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.57, val loss: 0.03, val f1: 0.47, duration: 5.0s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.82, val loss: 0.01, val f1: 0.80, duration: 5.7s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.8025096407280669\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling regular.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.07, val loss: 0.06, val f1: 0.10, duration: 5.4s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.58, val loss: 0.03, val f1: 0.59, duration: 5.2s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.84, val loss: 0.01, val f1: 0.84, duration: 5.8s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.8091264321129142\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling regular.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.08, val loss: 0.06, val f1: 0.15, duration: 5.7s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.57, val loss: 0.03, val f1: 0.61, duration: 5.3s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.83, val loss: 0.01, val f1: 0.81, duration: 5.1s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.8093670258487649\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling sqrt.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.02, val loss: 0.06, val f1: 0.02, duration: 5.4s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.44, val loss: 0.03, val f1: 0.46, duration: 5.2s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.78, val loss: 0.02, val f1: 0.72, duration: 4.9s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.7267715748666005\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling sqrt.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.03, val loss: 0.06, val f1: 0.05, duration: 5.0s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.41, val loss: 0.03, val f1: 0.42, duration: 5.0s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.78, val loss: 0.02, val f1: 0.73, duration: 5.0s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.7380685327165682\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling sqrt.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.02, val loss: 0.06, val f1: 0.03, duration: 5.1s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.41, val loss: 0.03, val f1: 0.44, duration: 5.2s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.78, val loss: 0.02, val f1: 0.77, duration: 5.3s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.7597821937618146\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling sqrt.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.02, val loss: 0.06, val f1: 0.03, duration: 4.8s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.43, val loss: 0.03, val f1: 0.42, duration: 5.2s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.77, val loss: 0.02, val f1: 0.76, duration: 5.1s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.7683959181145897\n",
      "\n",
      "\n",
      "\n",
      "Training gap 100 with oversampling sqrt.\n",
      "Transformer Model Best Params  | hd 235, nl 3, ne 128, ff 373, nh 4\n",
      "Epoch   1/ 10, train loss: 0.06, train f1: 0.03, val loss: 0.06, val f1: 0.05, duration: 5.2s\n",
      "Epoch   5/ 10, train loss: 0.03, train f1: 0.43, val loss: 0.03, val f1: 0.42, duration: 5.1s\n",
      "Epoch  10/ 10, train loss: 0.01, train f1: 0.77, val loss: 0.01, val f1: 0.81, duration: 5.1s\n",
      "\n",
      "\n",
      "\n",
      "Test F1 score: 0.7640331113203994\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversampling_training(oversampling, class_gaps, model_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
